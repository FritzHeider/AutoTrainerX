import streamlit as st
import requests
import time

st.set_page_config(page_title="GPT Fine-Tuning Tool", page_icon="ğŸ¤–", layout="wide")

st.title("ğŸ“„ AI Fine-Tuning & File Processing")

st.sidebar.header("âš™ï¸ Settings")
st.sidebar.text("Dark Mode Enabled ğŸŒ™")

# Upload Files
uploaded_files = st.file_uploader("ğŸ“¤ Upload Files", accept_multiple_files=True, type=["pdf", "txt", "csv"])

if uploaded_files:
    st.write("ğŸ“‚ **Processing Files...**")
    progress_bar = st.progress(0)
    
    uploaded_data = []
    
    for idx, file in enumerate(uploaded_files):
        files = {"files": (file.name, file.getvalue())}
        response = requests.post("http://localhost:8000/upload/", files=files)
        
        if response.status_code == 200:
            uploaded_data.append(response.json())
            progress_bar.progress((idx + 1) / len(uploaded_files))
        else:
            st.error(f"âŒ Failed to upload {file.name}: {response.json()['detail']}")

    st.success("âœ… All files processed successfully!")

# Display Uploaded Files
st.subheader("ğŸ“Š Uploaded File History")

uploaded_files = requests.get("http://localhost:8000/files").json()
if uploaded_files:
    for file in uploaded_files:
        st.write(f"ğŸ“„ {file['filename']} - ğŸ”— [View File]({file['s3_url']})")
else:
    st.write("No uploaded files found.")

# Query AI Model
st.subheader("ğŸ’¬ Query Fine-Tuned Model")
query_input = st.text_input("ğŸ” Ask the AI Model:")

if st.button("ğŸ§  Query AI"):
    if query_input.strip():
        with st.spinner("Thinking... ğŸ¤”"):
            response = requests.post("http://localhost:8000/query/", json={"prompt": query_input})
            if response.status_code == 200:
                st.success("âœ… AI Response:")
                st.write(response.json()["response"])
            else:
                st.error("âŒ Error querying model.")
    else:
        st.warning("âš ï¸ Please enter a query.")